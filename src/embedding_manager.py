"""
Gestionnaire d'embeddings utilisant BERT fran√ßais pour VoxThymio
Permet de g√©n√©rer des embeddings de descriptions en langage naturel
"""

import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel
from typing import List, Tuple, Dict, Any
import warnings

# Suppression des avertissements
warnings.filterwarnings("ignore", category=FutureWarning)


class EmbeddingManager:
    """
    G√©n√®re des embeddings en utilisant un mod√®le BERT fran√ßais √† partir de descriptions en langage naturel.
    """
    
    def __init__(self, model_name: str = "camembert-base"):
        """
        Initialise le gestionnaire d'embeddings.
        
        Args:
            model_name (str): Nom du mod√®le .
                             Par d√©faut: "camembert-base" (BERT fran√ßais)
        """

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"üîß Utilisation du p√©riph√©rique : {self.device}")
        
        try:
            # Chargement du mod√®le et tokenizer BERT fran√ßais
            print(f"üì• Chargement du mod√®le {model_name}...")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name)
            
            # Transfert sur le bon p√©riph√©rique
            self.model.to(self.device)
            self.model.eval()
            
            print("‚úÖ Mod√®le BERT fran√ßais charg√© et configur√©.")
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            raise RuntimeError(f"Impossible de charger le mod√®le {model_name}: {str(e)}")
    
    def generate_embedding(self, text: str) -> np.ndarray:
        """
        G√©n√®re un embedding pour un texte donn√©.
        
        Args:
            text (str): Texte √† encoder
            
        Returns:
            np.ndarray: Embedding du texte (vecteur de features)
        """
        # Nettoyage et pr√©paration du texte
        cleaned_text = self._clean_text(text)
        
        # Tokenisation
        inputs = self.tokenizer(
            cleaned_text,
            return_tensors='pt',
            truncation=True,
            padding=True,
            max_length=128
        )
        
        # D√©placement sur le bon p√©riph√©rique
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # G√©n√©ration de l'embedding
        with torch.no_grad():
            outputs = self.model(**inputs)
            # V√©rification de la pr√©sence de last_hidden_state
            if not hasattr(outputs, 'last_hidden_state'):
                raise ValueError("Le mod√®le ne retourne pas 'last_hidden_state'. V√©rifiez le mod√®le utilis√©.")
            
            # Utilisation de la moyenne des tokens comme repr√©sentation
            embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()

            # Normalisation de l'embedding
            embedding = embedding / np.linalg.norm(embedding) if np.linalg.norm(embedding) > 0 else embedding
        
        return embedding
    
    def generate_embeddings_batch(self, texts: List[str]) -> List[np.ndarray]:
        """
        G√©n√®re des embeddings pour une liste de textes.
        
        Args:
            texts (List[str]): Liste de textes √† encoder
            
        Returns:
            List[np.ndarray]: Liste des embeddings
        """

        embeddings = []
        for text in texts:
            embedding = self.generate_embedding(text)
            embeddings.append(embedding)
        return embeddings
    
    def _clean_text(self, text: str) -> str:
        """
        Nettoie et normalise le texte d'entr√©e.
        
        Args:
            text (str): Texte √† nettoyer
            
        Returns:
            str: Texte nettoy√©
        """
        if not text:
            return ""
        
        # Conversion en minuscules et suppression des espaces superflus
        cleaned = text.lower().strip()
        
        # Suppression des caract√®res de contr√¥le et normalisation des espaces
        cleaned = ' '.join(cleaned.split())
        
        return cleaned
    
    def get_embedding_info(self) -> Dict[str, Any]:
        """
        Retourne des informations sur le mod√®le d'embedding.
        
        Returns:
            Dict[str, Any]: Informations sur le mod√®le
        """
        return {
            "model_name": self.model.config.name_or_path if hasattr(self.model, 'config') else "Unknown",
            "embedding_dim": self.model.config.hidden_size if hasattr(self.model, 'config') else "Unknown",
            "device": str(self.device),
            "vocab_size": len(self.tokenizer) if self.tokenizer else "Unknown"
        }

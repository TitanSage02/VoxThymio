"""
Contr√¥leur vocal pour le robot Thymio
Pipeline : Audio ‚Üí Transcription ‚Üí Classification BERT ‚Üí Commande

D√©velopp√© par Esp√©rance AYIWAHOUN pour AI4Innov
Projet : VoxThymio - Syst√®me de contr√¥le intelligent du robot Thymio
"""

import speech_recognition as sr
import logging
from typing import Dict, Optional, List, Tuple
from dataclasses import dataclass
from enum import Enum
import json
import pathlib
import time

# Classification d'intention bas√©e sur BERT
from .intent_classifier import IntentClassifier


class VoiceCommandStatus(Enum):
    """√âtats possibles d'une commande vocale."""
    SUCCESS = "success"           # Commande reconnue avec succ√®s
    ERROR = "error"               # Erreur technique
    UNKNOWN_COMMAND = "unknown_command"  # Commande non reconnue
    NO_SPEECH = "no_speech"       # Pas de parole d√©tect√©e
    TIMEOUT = "timeout"           # Timeout d'√©coute


@dataclass
class VoiceCommand:
    """Repr√©sente une commande vocale reconnue.
    
    Attributes:
        text: Texte brut transcrit
        confidence: Niveau de confiance (0.0-1.0)
        status: Statut de la commande (voir VoiceCommandStatus)
        command_key: Cl√© de commande identifi√©e (si succ√®s)
    """
    text: str
    confidence: float
    status: VoiceCommandStatus
    command_key: Optional[str] = None


class VoiceController:
    """Contr√¥leur vocal pour le robot Thymio.
    
    Impl√©mente le pipeline complet:
    1. Capture audio (via microphone)
    2. Transcription (via Google Speech Recognition)
    3. Classification d'intention (via mod√®le BERT)
    4. Mappage vers commande Thymio
    """
    
    def __init__(self, intent_model_path: str = './intent_model'):
        """Initialise le contr√¥leur vocal avec le pipeline complet.
        
        Args:
            intent_model_path: Chemin vers le mod√®le BERT de classification d'intention
        """
        # Configuration du reconnaisseur vocal
        self.recognizer = sr.Recognizer()
        self.recognizer.energy_threshold = 300          # Sensibilit√© du microphone
        self.recognizer.dynamic_energy_threshold = True # Ajustement automatique
        self.recognizer.pause_threshold = 0.8           # Pause entre les mots (secondes)
        
        # Configuration des timeouts
        self.timeout = 10.0             # Timeout global de la session d'√©coute
        self.phrase_timeout = 10.0       # Timeout pour une phrase individuelle

        # Configuration du microphone
        self.microphone = None
        self.microphone_available = False
        
        # Journalisation et initialisation
        self._setup_logging()
        self._initialize_microphone()
        self._check_whisper_availability()

        # Chargement des commandes pour la reconnaissance vocale
        self._load_voice_commands()

        # Chargement du classifieur d'intention BERT
        self.logger.info(f"Chargement du mod√®le BERT depuis: {intent_model_path}")
        self.intent_classifier = IntentClassifier(model_path=intent_model_path)
    
    def _check_whisper_availability(self) -> None:
        """V√©rifie si Whisper est disponible et correctement install√©."""
        try:
            # Tenter d'acc√©der √† la m√©thode recognize_whisper
            if not hasattr(self.recognizer, 'recognize_whisper'):
                self.logger.warning("‚ö†Ô∏è Whisper n'est pas disponible dans cette version de SpeechRecognition")
                self.logger.info("‚ÑπÔ∏è Installation recommand√©e: pip install --upgrade speechrecognition openai-whisper")
                return False
            
            self.logger.info("‚úÖ Whisper est disponible pour la reconnaissance vocale locale")
        
            return True
        
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la v√©rification de Whisper: {e}")
            return False
    
    def _load_voice_commands(self) -> None:
        """Charge les commandes vocales depuis le fichier JSON.
        
        Le mod√®le BERT est d√©j√† entra√Æn√© pour pr√©dire directement
        les commandes qui sont d√©finies dans commands.json.
        """
        try:
            # Chemin vers commands.json
            commands_path = pathlib.Path(__file__).parent.parent / "commands.json"
            
            with open(commands_path, 'r', encoding='utf-8') as f:
                commands = json.load(f)
                
            # Stocke les commandes disponibles - pas besoin de mapping complexe
            # puisque le mod√®le BERT renvoie directement ces commandes
            self.available_commands = list(commands.keys())
            
            # Initialise un dictionnaire vide - sert uniquement √† la compatibilit√©
            self.voice_commands = {}
            
            self.logger.info(f"‚úÖ {len(commands)} commandes charg√©es depuis {commands_path}")
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du chargement des commandes: {e}")
            self.available_commands = [
                "avancer", "reculer", "arreter", "tourner_gauche", "tourner_droite",
                "led_rouge", "led_vert", "led_bleu", "led_eteindre", "quitter"
            ]
            self.logger.info("‚ö†Ô∏è Utilisation des commandes par d√©faut uniquement")
            
    def _initialize_microphone(self) -> None:
        """Initialise le microphone."""
        try:
            self.microphone = sr.Microphone()
            self.microphone_available = True

            # Calibrage pour le bruit ambiant
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1.5)
            
            self.logger.info("‚úÖ Microphone initialis√© et calibr√©")
        
        except Exception as e:
            self.logger.error(f"‚ùå Erreur microphone: {e}")
            self.microphone_available = False
    
    def _setup_logging(self) -> None:
        """Configure le logging."""
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def listen_for_command(self) -> VoiceCommand:
        """√âcoute, reconna√Æt et interpr√®te une commande vocale.
        
        Pipeline complet:
        1. Capture audio via microphone
        2. Transcription via Google Speech Recognition
        3. Classification d'intention via mod√®le BERT
        4. Mappage vers commande Thymio
        
        Returns:
            VoiceCommand: Objet contenant le r√©sultat du traitement
        """
        # V√©rification de la disponibilit√© du microphone
        if not self.microphone_available:
            return VoiceCommand(
                text="", 
                confidence=0.0, 
                status=VoiceCommandStatus.ERROR
            )

        try:
            # 1. CAPTURE AUDIO
            start_time = time.time()
            self.logger.info("üé§ Capture audio en cours...")
            
            with self.microphone as source:
                audio = self.recognizer.listen(
                    source, 
                    timeout=self.timeout,
                    phrase_time_limit=self.phrase_timeout
                )
            
            capture_duration = time.time() - start_time
            self.logger.info(f"‚úì Audio captur√© ({capture_duration:.1f}s)")
            
            # 2. TRANSCRIPTION VOCALE
            self.logger.info("üîÑ Transcription en cours...")
            try:
                raise AttributeError("Passage forc√© √† l'usage de Whisper") 
            

                # Utilisation de Whisper pour la reconnaissance vocale locale
                text = self.recognizer.recognize_whisper(audio, language="fr")
                self.logger.info(f"‚úì Texte transcrit : '{text}'")

            except AttributeError:
                text = self.recognizer.recognize_google(audio, language="fr-FR")
                self.logger.info(f"‚úì Texte transcrit : '{text}'")
            
            except Exception as e:
                self.logger.error(f"‚ùå Erreur de transcription Whisper: {e}")
                return VoiceCommand(
                    text="", 
                    confidence=0.0, 
                    status=VoiceCommandStatus.ERROR
                )
            
            if not text:
                return VoiceCommand(
                    text="", 
                    confidence=0.0, 
                    status=VoiceCommandStatus.NO_SPEECH
                )
            
            self.logger.info(f"‚úì Texte transcrit: '{text}'")
            
            # 3. CLASSIFICATION D'INTENTION VIA BERT
            try:
                self.logger.info("üß† Classification d'intention en cours...")
                predicted_intent = self.intent_classifier.predict(text)
                self.logger.info(f"‚úì Intention identifi√©e: '{predicted_intent}'")
                
                # 4. V√âRIFICATION DE LA COMMANDE PR√âDITE
                if predicted_intent in self.available_commands:
                    self.logger.info(f"‚úì Commande valide: '{predicted_intent}'")
                    
                    return VoiceCommand(
                        text=text,
                        confidence=1.0,  # Confiance fix√©e √† 1.0 pour BERT
                        status=VoiceCommandStatus.SUCCESS,
                        command_key=predicted_intent
                    )
                else:
                    self.logger.warning(f"‚ö†Ô∏è Commande non reconnue: '{predicted_intent}'")
                    return VoiceCommand(
                        text=text,
                        confidence=1.0,
                        status=VoiceCommandStatus.UNKNOWN_COMMAND
                    )
            except Exception as e:
                self.logger.error(f"‚ùå Erreur de classification: {e}")
                return VoiceCommand(
                    text=text,
                    confidence=0.0,
                    status=VoiceCommandStatus.ERROR
                )

        except sr.UnknownValueError:
            self.logger.warning("‚ö†Ô∏è Parole non reconnue")
            return VoiceCommand(
                text="", 
                confidence=0.0, 
                status=VoiceCommandStatus.NO_SPEECH
            )
        
        except sr.WaitTimeoutError:
            self.logger.warning("‚ö†Ô∏è Timeout d'√©coute")
            return VoiceCommand(
                text="", 
                confidence=0.0, 
                status=VoiceCommandStatus.TIMEOUT
            )
        
        except Exception as e:
            self.logger.error(f"‚ùå Erreur: {e}")
            return VoiceCommand(
                text="", 
                confidence=0.0, 
                status=VoiceCommandStatus.ERROR
            )

    def is_microphone_available(self) -> bool:
        """V√©rifie si le microphone est disponible pour le contr√¥le vocal.
        
        Returns:
            bool: True si un microphone est disponible, False sinon
        """
        return self.microphone_available
    
    def list_commands(self) -> List[str]:
        """Retourne la liste des commandes disponibles.
        
        Returns:
            List[str]: Liste des commandes disponibles
        """
        return self.available_commands.copy()
    
    def get_available_commands_by_category(self) -> Dict[str, List[str]]:
        """Organise les commandes disponibles par cat√©gorie pour l'affichage.
        
        Returns:
            Dict[str, List[str]]: Dictionnaire cat√©gorie ‚Üí liste de commandes
        """
        categories = {
            "Mouvement": [],
            "LEDs": [],
            "Sons": [],
            "Syst√®me": [],
            "Autres": []
        }
        
        # Cat√©gorisation des commandes
        for cmd in self.available_commands:
            if any(x in cmd for x in ["avancer", "reculer", "tourner", "pivoter", "demi_tour"]):
                categories["Mouvement"].append(cmd)
            elif any(x in cmd for x in ["led", "leds"]):
                categories["LEDs"].append(cmd)
            elif any(x in cmd for x in ["son", "note", "volume"]):
                categories["Sons"].append(cmd)
            elif cmd == "quitter" or cmd == "arreter":
                categories["Syst√®me"].append(cmd)
            else:
                categories["Autres"].append(cmd)
        
        return categories

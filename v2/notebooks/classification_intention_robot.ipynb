{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TitanSage02/Vox-Thymio/blob/main/v2/notebooks/classification_intention_robot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c854fad",
      "metadata": {
        "id": "5c854fad"
      },
      "source": [
        "# Classification d'intention pour Thymio - Notebook complet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a345bfa0",
      "metadata": {
        "id": "a345bfa0"
      },
      "source": [
        "Ce notebook contient toutes les étapes pour entraîner un modèle de classification d'intentions basé sur BERT, depuis l'exploration des données jusqu'à la sauvegarde du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9261584d",
      "metadata": {
        "id": "9261584d"
      },
      "source": [
        "## Étapes couvertes :\n",
        "1. Chargement et exploration du jeu de données\n",
        "2. Prétraitement du texte\n",
        "3. Tokenization avec `BERT`\n",
        "4. Entraînement du modèle\n",
        "5. Évaluation sur un jeu de test\n",
        "6. Sauvegarde du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea5d25f",
      "metadata": {
        "id": "bea5d25f"
      },
      "source": [
        "## 1. Chargement du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad032ab",
      "metadata": {
        "id": "bad032ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Chargement des données\n",
        "df = pd.read_csv('intent_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "686de8e0",
      "metadata": {
        "id": "686de8e0"
      },
      "source": [
        "## 2. Exploration des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34359a59",
      "metadata": {
        "id": "34359a59"
      },
      "outputs": [],
      "source": [
        "# Taille du jeu de données\n",
        "print(f\"Nombre d'exemples : {len(df)}\")\n",
        "\n",
        "# Répartition des classes\n",
        "df['label'].value_counts().plot(kind='bar', figsize=(12,4), title=\"Répartition des intentions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342aff25",
      "metadata": {
        "id": "342aff25"
      },
      "source": [
        "## 3. Prétraitement du texte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7fcf0b7",
      "metadata": {
        "id": "d7fcf0b7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\sàâçéèêëîïôûùüÿñæœ'-]\", '', text)\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78806a8",
      "metadata": {
        "id": "c78806a8"
      },
      "source": [
        "## 4. Préparation des données pour BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e017c0de",
      "metadata": {
        "id": "e017c0de"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Encodage des étiquettes\n",
        "le = LabelEncoder() # One-Hot Encoding à voir après\n",
        "df['label_id'] = le.fit_transform(df['label'])\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label_id'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "738d8485",
      "metadata": {
        "id": "738d8485"
      },
      "source": [
        "## 5. Dataset Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041189f5",
      "metadata": {
        "id": "041189f5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class IntentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} | {'labels': torch.tensor(self.labels[idx])}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IntentDataset(train_encodings, list(y_train))\n",
        "test_dataset = IntentDataset(test_encodings, list(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088f8ba7",
      "metadata": {
        "id": "088f8ba7"
      },
      "source": [
        "## 6. Entraînement du modèle BERT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "iTKOjTavXfap"
      },
      "id": "iTKOjTavXfap",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243114a7",
      "metadata": {
        "id": "243114a7"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Define metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    accuracy = evaluate.load(\"accuracy\")\n",
        "    f1 = evaluate.load(\"f1\")\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    f1 = f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le.classes_))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=25,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=5,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,  # Load the best model when training ends\n",
        "    metric_for_best_model=\"f1\",  # Use f1 score to determine the best model\n",
        "    greater_is_better=True # Higher f1 score is better\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # Stop if f1 score doesn't improve for 3 epochs\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9249599a",
      "metadata": {
        "id": "9249599a"
      },
      "source": [
        "## 7. Évaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice de confusion\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predictions on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Extract predicted labels\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iairmfFk9BF3"
      },
      "id": "iairmfFk9BF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3cc37a",
      "metadata": {
        "id": "5c3cc37a"
      },
      "outputs": [],
      "source": [
        "# Evaluation du modèle\n",
        "\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8e513e",
      "metadata": {
        "id": "bb8e513e"
      },
      "source": [
        "## 8. Sauvegarde du modèle et de l’encodeur de labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1d609d",
      "metadata": {
        "id": "bf1d609d"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('./intent_model')\n",
        "tokenizer.save_pretrained('./intent_model')\n",
        "\n",
        "import joblib\n",
        "joblib.dump(le, './intent_model/label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8684ec",
      "metadata": {
        "id": "bb8684ec"
      },
      "source": [
        "## Prêt pour l'inférence !"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}